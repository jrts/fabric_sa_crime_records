{"cells":[{"cell_type":"code","source":["%run nb_03_fact_record_wrangler"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:25.6711666Z","session_start_time":null,"execution_start_time":"2025-07-06T03:26:31.3855244Z","execution_finish_time":"2025-07-06T03:26:31.4403379Z","parent_msg_id":"f9fbe1b2-35d9-4224-a71b-9b5e0a75e88c"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"98a041c6-d925-4d96-b109-ec3426258ee6"},{"cell_type":"code","source":["import unittest\n","import datetime\n","from pyspark.sql import SparkSession, Row\n","from pyspark.sql.types import StructType, StructField, DateType, StringType, ShortType, IntegerType\n","from pyspark.testing.utils import assertDataFrameEqual, assertSchemaEqual\n","from delta.tables import DeltaTable\n","\n","class TestFactRecordWrangler(unittest.TestCase):\n","\n","    @classmethod\n","    def setUpClass(cls):\n","\n","        cls.spark = SparkSession.builder.appName('fact_record_test').getOrCreate()\n","        cls.delta_table_name = 'fact_record_test'\n","        FactRecordWrangler.create_delta_table(cls.spark, cls.delta_table_name)\n","        cls.spark.sql(f'DELETE FROM {cls.delta_table_name}')\n","\n","    def expected_schema(self):\n","        return StructType([\n","            StructField('ReportedDate', DateType()),\n","            StructField('Suburb', StringType()),\n","            StructField('Postcode', ShortType()),\n","            StructField('DescID', IntegerType()),\n","            StructField('Count', IntegerType()),\n","        ])\n","\n","    def test_extract_silver_df(self):\n","\n","        # Prepare silver_df and dim_desc_table\n","        silver_data = [\n","            Row(ReportedDate=datetime.date(2023, 12, 5), Suburb='A', Postcode=1234, LevelOneDesc='L1', LevelTwoDesc='L2', LevelThreeDesc='L3', Count=5),\n","            Row(ReportedDate=datetime.date(2023, 12, 6), Suburb='B', Postcode=5678, LevelOneDesc='L4', LevelTwoDesc='L5', LevelThreeDesc='L6', Count=7),\n","        ]\n","        silver_schema = StructType([\n","            StructField('ReportedDate', DateType()),\n","            StructField('Suburb', StringType()),\n","            StructField('Postcode', ShortType()),\n","            StructField('LevelOneDesc', StringType()),\n","            StructField('LevelTwoDesc', StringType()),\n","            StructField('LevelThreeDesc', StringType()),\n","            StructField('Count', IntegerType()),\n","        ])\n","        silver_df = spark.createDataFrame(silver_data, silver_schema)\n","\n","        desc_data = [\n","            Row(LevelOneDesc='L1', LevelTwoDesc='L2', LevelThreeDesc='L3', DescID=1),\n","            Row(LevelOneDesc='L4', LevelTwoDesc='L5', LevelThreeDesc='L6', DescID=2),\n","        ]\n","        desc_schema = StructType([\n","            StructField('LevelOneDesc', StringType()),\n","            StructField('LevelTwoDesc', StringType()),\n","            StructField('LevelThreeDesc', StringType()),\n","            StructField('DescID', IntegerType()),\n","        ])\n","        dim_desc_table = spark.createDataFrame(desc_data, desc_schema)\n","        result_df = FactRecordWrangler.extract_silver_df(silver_df, dim_desc_table)\n","\n","        expected_data = [\n","            (datetime.date(2023, 12, 5), 'A', 1234, 1, 5),\n","            (datetime.date(2023, 12, 6), 'B', 5678, 2, 7),\n","        ]\n","        expected_df = spark.createDataFrame(expected_data, self.expected_schema())\n","        assertDataFrameEqual(result_df, expected_df)\n","\n","    def test_create_delta_table_schema(self):\n","\n","        table_schema = spark.table(self.delta_table_name).schema\n","        assertSchemaEqual(table_schema, self.expected_schema())\n","\n","    def test_upsert_delta_table_insert(self):\n","        # Insert a new row\n","        data = [\n","            (datetime.date(2023, 12, 5), 'A', 1234, 1, 5),\n","        ]\n","        schema = self.expected_schema()\n","        df = spark.createDataFrame(data, schema)\n","        delta_table = DeltaTable.forName(spark, self.delta_table_name)\n","\n","        FactRecordWrangler.upsert_delta_table(delta_table, df)\n","        result_df = spark.sql(f'SELECT * FROM {self.delta_table_name}')\n","\n","        assert result_df.count() == 1\n","        row = result_df.first()\n","        assert row['ReportedDate'] == datetime.date(2023, 12, 5)\n","        assert row['Suburb'] == 'A'\n","        assert row['Postcode'] == 1234\n","        assert row['DescID'] == 1\n","        assert row['Count'] == 5\n","\n","        spark.sql(f'DELETE FROM {self.delta_table_name}')\n","\n","    def test_upsert_delta_table_update(self):\n","\n","        # Insert, then update Count\n","        schema = self.expected_schema()\n","        data = [\n","            (datetime.date(2023, 12, 5), 'A', 1234, 1, 5),\n","        ]\n","        df = spark.createDataFrame(data, schema)\n","        delta_table = DeltaTable.forName(spark, self.delta_table_name)\n","\n","        FactRecordWrangler.upsert_delta_table(delta_table, df)\n","\n","        # Update Count\n","        update_data = [\n","            (datetime.date(2023, 12, 5), 'A', 1234, 1, 10),\n","        ]\n","        update_df = spark.createDataFrame(update_data, schema)\n","\n","        FactRecordWrangler.upsert_delta_table(delta_table, update_df)\n","        result_df = spark.sql(f'SELECT * FROM {self.delta_table_name}')\n","        \n","        assert result_df.count() == 1\n","        row = result_df.first()\n","        assert row['Count'] == 10\n","\n","        spark.sql(f'DELETE FROM {self.delta_table_name}')\n","\n","    def test_upsert_delta_table_no_duplicate(self):\n","\n","        # Insert the same row again, should not duplicate\n","        data = [\n","            (datetime.date(2023, 12, 5), 'A', 1234, 1, 5),\n","        ]\n","        schema = self.expected_schema()\n","        df = spark.createDataFrame(data, schema)\n","        delta_table = DeltaTable.forName(spark, self.delta_table_name)\n","\n","        FactRecordWrangler.upsert_delta_table(delta_table, df)\n","        FactRecordWrangler.upsert_delta_table(delta_table, df)\n","        \n","        result_df = spark.sql(f'SELECT * FROM {self.delta_table_name}')\n","        assert result_df.count() == 1\n","\n","        spark.sql(f'DELETE FROM {self.delta_table_name}')\n","\n","    def test_upsert_delta_table_multiple(self):\n","\n","        # Insert multiple new rows\n","        data = [\n","            (datetime.date(2023, 12, 5), 'A', 1234, 1, 5),\n","            (datetime.date(2023, 12, 6), 'B', 5678, 2, 7),\n","        ]\n","        schema = self.expected_schema()\n","        df = spark.createDataFrame(data, schema)\n","        delta_table = DeltaTable.forName(spark, self.delta_table_name)\n","\n","        FactRecordWrangler.upsert_delta_table(delta_table, df)\n","\n","        result_df = spark.sql(f'SELECT * FROM {self.delta_table_name}')\n","        assert result_df.count() == 2\n","\n","        spark.sql(f'DELETE FROM {self.delta_table_name}')\n","\n","    @classmethod\n","    def tearDownClass(cls):\n","\n","        cls.spark.sql(f'DROP TABLE IF EXISTS {cls.delta_table_name}')\n","        cls.spark.stop()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:25.8232522Z","session_start_time":null,"execution_start_time":"2025-07-06T03:26:31.4427379Z","execution_finish_time":"2025-07-06T03:26:33.7151472Z","parent_msg_id":"e9c7f3d9-9814-4e85-825f-f3467010bc5e"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a0adf049-598b-41c4-84a7-a813728fe7f0"},{"cell_type":"code","source":["test_case = TestFactRecordWrangler()\n","TestFactRecordWrangler.setUpClass()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:25.8986667Z","session_start_time":null,"execution_start_time":"2025-07-06T03:26:33.7174495Z","execution_finish_time":"2025-07-06T03:26:52.294719Z","parent_msg_id":"89e1f18c-bf64-421a-902c-b4f8401f44e8"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6718cfb4-585b-4389-bf2a-a00d7c889909"},{"cell_type":"code","source":["test_case.test_extract_silver_df()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:25.9755657Z","session_start_time":null,"execution_start_time":"2025-07-06T03:26:52.2969675Z","execution_finish_time":"2025-07-06T03:26:55.6607359Z","parent_msg_id":"b18beff9-0bb3-4351-8df0-eef2d2d2513e"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"00b0adce-ee7d-41ec-abe7-a9cd1c6226e8"},{"cell_type":"code","source":["test_case.test_create_delta_table_schema()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:26.0410209Z","session_start_time":null,"execution_start_time":"2025-07-06T03:26:55.6629954Z","execution_finish_time":"2025-07-06T03:26:56.4413567Z","parent_msg_id":"c452eb43-d909-43e6-b17c-2d061397d69b"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1cc27482-ff46-4cc2-9a94-73db8dfdf885"},{"cell_type":"code","source":["test_case.test_upsert_delta_table_insert()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:26.0453767Z","session_start_time":null,"execution_start_time":"2025-07-06T03:26:56.4436548Z","execution_finish_time":"2025-07-06T03:27:08.2313323Z","parent_msg_id":"320247b9-73fa-419c-8326-9e60fc8c08ed"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"50220186-8b41-4583-8872-36c68f7aee6f"},{"cell_type":"code","source":["test_case.test_upsert_delta_table_update()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:26.1311714Z","session_start_time":null,"execution_start_time":"2025-07-06T03:27:08.2338263Z","execution_finish_time":"2025-07-06T03:27:24.3481136Z","parent_msg_id":"b1278268-a782-4ae2-af58-fefb067c3da4"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac8d7a78-75e4-43ce-89ed-c7c27e9d2aeb"},{"cell_type":"code","source":["test_case.test_upsert_delta_table_no_duplicate()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:26.2338196Z","session_start_time":null,"execution_start_time":"2025-07-06T03:27:24.3507375Z","execution_finish_time":"2025-07-06T03:27:36.7116981Z","parent_msg_id":"7b8f9c80-9a82-4aa6-9d6d-8c967e3914b0"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1b2c7cf4-e115-49d7-b25f-13d05caa208c"},{"cell_type":"code","source":["test_case.test_upsert_delta_table_multiple()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:26.2780615Z","session_start_time":null,"execution_start_time":"2025-07-06T03:27:36.7143151Z","execution_finish_time":"2025-07-06T03:27:44.5958315Z","parent_msg_id":"a2f1c8d3-d27b-4abe-991b-f9bf22ba9a94"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5d0517c2-8a87-47fe-be17-2c2f53a672c7"},{"cell_type":"code","source":["TestFactRecordWrangler.tearDownClass()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"fd9a733b-21e8-4c42-89a2-aac6afe0b551","normalized_state":"finished","queued_time":"2025-07-06T03:26:26.2823552Z","session_start_time":null,"execution_start_time":"2025-07-06T03:27:44.5982937Z","execution_finish_time":"2025-07-06T03:27:46.8948162Z","parent_msg_id":"74386490-532e-4eae-b4f7-ecbf4136f183"},"text/plain":"StatementMeta(, fd9a733b-21e8-4c42-89a2-aac6afe0b551, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"25918d61-9eb9-43f3-9e06-bd863476206e\",\"activityId\":\"fd9a733b-21e8-4c42-89a2-aac6afe0b551\",\"applicationId\":\"application_1751771754967_0001\",\"jobGroupId\":\"12\",\"advices\":{\"info\":1}}"}},"id":"4eb5fb89-1bb7-429d-a6c3-e7acf760b365"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"41aecb0b-4945-4e96-934c-4da7f3b43342"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"d1f1cbd6-208e-47ed-af7f-a4b573719fc3"}],"default_lakehouse":"d1f1cbd6-208e-47ed-af7f-a4b573719fc3","default_lakehouse_name":"lh_sa_crime_test","default_lakehouse_workspace_id":"d9b10c93-1a77-400b-9b7a-9b49740a2c56"}}},"nbformat":4,"nbformat_minor":5}